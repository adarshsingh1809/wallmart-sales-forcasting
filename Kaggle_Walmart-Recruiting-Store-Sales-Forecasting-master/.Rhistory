f5
f5 <- rep(NA,5)
f5[insert_ind] <- z[good_ind]
f5
date <- "2012-05-05"
x <- unlist(strsplit(date, '-'))
x
type(x)
class(x)
?gbm
require(gbm)
?gbm
getwd()
?gc
gc(verbose = getOption("verbose"), reset = FALSE)
gc(verbose =F, reset = FALSE)
gc(verbose =T, reset = FALSE)
?suppressMessages
suppressMessages(gc(reset=T))
require(gbm)
?gbm
dept_type1 = c(1, 18)
dept_type2 = c(2, 4, 8, 80, 81, 87, 90, 91, 92, 93, 97, 98)
dept_type3 = c(3)
dept_type4 = c(5, 6, 7, 14, 17, 21, 22, 23, 25, 26, 27, 29,
32, 46, 55, 59, 72, 82, 85, 99)
dept_type5 = c(9, 24, 31, 33, 34, 35, 36, 52)
dept_type6 = c(12, 16, 56, 95)
dept_type7 = c(13, 20, 42, 49, 83)
dept_type8 = c(41, 44)
dept_type9 = c(67)
dept_type10 = c(71, 74)
all_depts = list(dept_type1, dept_type2, dept_type3, dept_type4, dept_type5,
dept_type6, dept_type7, dept_type8, dept_type9, dept_type10)
all <- unlist(all_depts)
all
unique(all)
setwd("E:/Walmart/R/git-final")
load('./data/training_testing_data_V1.RData')
all_depts <- sort(unique(dfTest$Dept))
all_depts
all_depts <- sort(unique(as.numeric(dfTest$Dept)))
all_depts
all
all_depts[!all_depts %in% all]
dept_type1 = c(1, 18)
dept_type2 = c(2, 4, 8, 79, 80, 81, 87, 90, 91, 92, 93, 97, 98)
dept_type3 = c(3)
dept_type4 = c(5, 6, 7, 14, 17, 21, 22, 23, 25, 26, 27, 29,
32, 46, 48, 55, 59, 72, 82, 85, 99)
dept_type5 = c(9, 10, 19, 30, 34, 35, 37, 52)
dept_type6 = c(24, 31, 33)
dept_type7 = c(11, 36)
dept_type8 = c(12, 16, 56, 95)
dept_type9 = c(13, 20, 42, 49, 83)
dept_type10 = c(28, 40)
dept_type11 = c(41, 44)
dept_type12 = c(67)
dept_type13 = c(71, 74)
all_depts = list(dept_type1, dept_type2, dept_type3, dept_type4, dept_type5,
dept_type6, dept_type7, dept_type8, dept_type9, dept_type10,
dept_type11, dept_type12, dept_type13)
all_depts[!all_depts %in% all]
all <- unlist(all_depts)
all_depts <- sort(unique(as.numeric(dfTest$Dept)))
all_depts[!all_depts %in% all]
unique(dfTest$Store[dfTest$Dept==15])
unique(dfTest$Store[dfTest$Dept==38])
unique(dfTest$Store[dfTest$Dept==39])
unique(dfTest$Store[as.numeric(dfTest$Dept)==39])
unique(dfTrain$Store[dfTrain$Dept==38])
unique(dfTrain$Store[dfTrain$Dept==15])
unique(dfTrain$Store[dfTrain$Dept==39])
unique(dfTrain$Store[as.numeric(dfTrain$Dept)==39])
unique(dfTrain$Store[(dfTrain$Dept)==39])
table(dfTest$Dept)
table(dfTrain$Dept)
(dfTrain$Store[(dfTrain$Dept)==39])
table(dfTrain$Store)
all_depts[!all_depts %in% all]
all_depts[!all_depts %in% all]
##########
## Main ##
##########
dept_type1 = c(1, 18)
dept_type2 = c(2, 4, 8, 60, 79, 80, 81, 87, 90, 91, 92, 93, 97, 98)
dept_type3 = c(3)
dept_type4 = c(5, 6, 7, 14, 17, 21, 22, 23, 25, 26, 27, 29,
32, 46, 48, 55, 59, 72, 82, 85, 99)
dept_type5 = c(9, 10, 19, 30, 34, 35, 37, 52)
dept_type6 = c(24, 31, 33)
dept_type7 = c(11, 36)
dept_type8 = c(12, 16, 56, 95)
dept_type9 = c(13, 20, 42, 49, 50, 83)
dept_type10 = c(28, 40)
dept_type11 = c(41, 44)
dept_type12 = c(67)
dept_type13 = c(71, 74)
all_depts = list(dept_type1, dept_type2, dept_type3, dept_type4, dept_type5,
dept_type6, dept_type7, dept_type8, dept_type9, dept_type10,
dept_type11, dept_type12, dept_type13)
all <- unlist(all_depts)
all_depts <- sort(unique(as.numeric(dfTest$Dept)))
all_depts[!all_depts %in% all]
table(dfTrain$Store)
table(dfTrain$Dept)
table(dfTest$Dept)
list(all_depts[!all_depts %in% all])
all_depts <- sort(unique((dfTest$Dept)))
all_depts[!all_depts %in% all]
all
all_depts <- sort(as.numeric(unique((dfTest$Dept)))
all_depts <- sort(as.numeric(unique(dfTest$Dept)))
all_depts[!all_depts %in% all]
all_depts
all_depts <- sort((unique(dfTest$Dept))
all_depts <- sort(unique(dfTest$Dept))
all_depts
length(all_depts)
length(all)
all_depts[!all_depts %in% all]
dept_type1 = c(1, 18)
dept_type2 = c(2, 4, 8, 60, 79, 80, 81, 87, 90, 91, 92, 93, 94, 97, 98)
dept_type3 = c(3)
dept_type4 = c(5, 6, 7, 14, 17, 21, 22, 23, 25, 26, 27, 29,
32, 46, 48, 55, 59, 72, 82, 85, 96, 99)
dept_type5 = c(9, 10, 19, 30, 34, 35, 37, 52)
dept_type6 = c(24, 31, 33)
dept_type7 = c(11, 36)
dept_type8 = c(12, 16, 56, 95)
dept_type9 = c(13, 20, 42, 49, 50, 83)
dept_type10 = c(28, 40)
dept_type11 = c(41, 44)
dept_type12 = c(67)
dept_type13 = c(71, 74)
all_depts = list(dept_type1, dept_type2, dept_type3, dept_type4, dept_type5,
dept_type6, dept_type7, dept_type8, dept_type9, dept_type10,
dept_type11, dept_type12, dept_type13)
all <- unlist(all_depts)
all_depts <- sort(unique(dfTest$Dept))
all_depts[!all_depts %in% all]
all_depts <- sort(unique(dfTest$Dept))
all_depts
all_depts[1]
all_depts[1]==1
all_depts[1]==as.numeric(1)
dept_type1 = c(1, 18)
dept_type2 = c(2, 4, 8, 60, 79, 80, 81, 87, 90, 91, 92, 93, 94, 97, 98)
dept_type3 = c(3)
dept_type4 = c(5, 6, 7, 14, 17, 21, 22, 23, 25, 26, 27, 29,
32, 46, 48, 55, 59, 72, 82, 85, 96, 99)
dept_type5 = c(9, 10, 19, 30, 34, 35, 37, 52)
dept_type6 = c(24, 31, 33)
dept_type7 = c(11, 36)
dept_type8 = c(12, 16, 56, 95)
dept_type9 = c(13, 20, 42, 49, 50, 83)
dept_type10 = c(28, 40)
dept_type11 = c(41, 44)
dept_type12 = c(67)
dept_type13 = c(71, 74)
depts_list = list(dept_type1, dept_type2, dept_type3, dept_type4, dept_type5,
dept_type6, dept_type7, dept_type8, dept_type9, dept_type10,
dept_type11, dept_type12, dept_type13)
# all <- unlist(all_depts)
depts_test <- sort(unique(dfTest$Dept))
dept_alone <- depts_test[!depts_test %in% unlist(depts_list)]
dept_alone
depts_list
dept_alone
as.list(dept_alone)
depts_list2 <- c(depts_list, as.list(dept_alone))
depts_list2
?factor
dept_alone
as.character(dept_alone)
as.numeric(as.character(dept_alone))
depts_test <- sort(unique(dfTest$Dept))
depts_test <- as.numeric(as.character(depts_test))
dept_alone <- depts_test[!depts_test %in% unlist(depts_list)]
depts_list2 <- c(depts_list, as.list(dept_alone))
depts_list2
depts_test <- sort(unique(dfTest$Dept))
depts_test
depts_test <- as.numeric(as.character(depts_test))
depts_test
depts_list[[1]]
depts_list[[2]]
for(dept in depts_list[[1]]){print dept}
for(dept in depts_list[[1]]){print(dept)}
for(dept in depts_list){print(dept)}
for(dept in depts_list[1){print(dept)}
for(dept in depts_list[1]){print(dept)}
depts_list[1]
class(depts_list[1])
class(depts_list[[1]])
depts_list[[1]]
depts_list[1]
paste0(depts_list[1])
paste(depts_list[1])
paste(depts_list[1], sep='')
paste(unlist(depts_list[1]), sep='')
cat(paste(unlist(depts_list[1]), sep=''))
cat(unlist(depts_list[1]), sep='')
cat(unlist(depts_list[1]), sep=' ')
unlist(depts_list[1])
paste(unlist(depts_list[1]), sep=' ')
print(paste(unlist(depts_list[1]), sep=' '))
print(paste(unlist(depts_list[1]), sep=''))
print(cat(unlist(depts_list[1]), sep=''))
print(cat(unlist(depts_list[1]), sep=' '))
(cat(unlist(depts_list[1]), sep=' '))
(cat(unlist(depts_list[1]), sep=''))
cat(unlist(depts_list[1]), sep=' ')
cat((depts_list[1]), sep=' ')
cat(unlist(depts_list[1]), sep=' ')
#####################################################################
# Description:
# Train GBM for store weekly sales forecasting, plot the predicted
# weekly sales (also save in png format), and make submission in the
# required csv format.
# Version: 1.0
#
# Kaggle contest description, rules and data:
# http://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting
#
# Author: Chenglong Chen <c.chenglong@gmail.com>
# Contact:
# http://weibo.com/denny2cd
# https://github.com/ChenglongChen
# http://www.kaggle.com/users/102203/yr
#####################################################################
# Code description:
# This code uses the observation that for the same dept, the weekly
# sales are very similar despite of different magnitudes across all
# the stores. So, it seems that the same dept sales the same kind of
# products?
# To see this, use file <visualize_weekly_sales.R>
#
# This code also plots the predicted weekly sales and saves them in
# png format in a new created folder in the current working dircetory.
#
# Using the params setting in this code, you should yield WMAE around
# 2500. Feel free to play with those params to see how far you can go!
#
# NOTE:
# In this version (version 1.0), some depts are not well modeled.
# Take dept=1 for example. The periodic artifact is not well caputred.
# However, version 2.0 seems doing a job for dept=1. So, motivated by
# such observation, I manually post-process the predictions of version
# 1.0, and replace some of those with the corresponding predictions
# from version 2.0, despite of the fact that version 2.0 yields higher
# overall WMAE. By replacing the obviously dept=1, WMAE reduces about
# 10~15.
# From a practical aspect, however, better approach should be taken
# to ensemble the predictions from these two :)
#
# For further improvement, one can use models/features that can well
# capature the increasing/decaresing trend+seasonal periodic artifact
# in the weekly sales time series data.
# Code for the Global Energy Forecasting Competition 2012 may be a
# good start:
# https://github.com/jamesrobertlloyd/GEFCOM2012
#####################################################################
rm(list=ls(all=TRUE))
gc(reset=TRUE)
######################
## Helper Functions ##
######################
#### This function predict Weekly_Sales with trained gbm model
predTest <- function(gbm_, dfTest, dfTrain, inverse_transform, lambda=NULL){
store_test <- sort(unique(dfTest$Store))
store_train <- sort(unique(dfTrain$Store))
pred_test <- NULL
# get the number of best iteration using cross-validation
best.iter <- gbm.perf(gbm_, method="cv", plot.it =FALSE)
for(store in store_test){
ind_ <- which(dfTest$Store == store)
# NOte that for some dept, e.g., 99, there are some stores with dept 99 in
# the test data which however is NOT in the training data. So, we have to
# check this out.
if(store %in% store_train){
# we explicityly specify the best iteration to avoid printing mess around
p <- predict(gbm_, newdata=dfTest[ind_,], n.trees=best.iter)
if(!is.null(lambda)){
p <- inverse_transform(p, lambda)
}else{
p <- inverse_transform(p)
}
pred_test <- c(pred_test, p)
}else{
# we have no data corresponding to this combination of store & dept in
# training data. Since we have store as factor, this will raise error.(?)
# Here, we use a simple strategy by circling the store factor in this
# training data, and use that to replace the current non-exist store factor
# (from the test data). We then make prediction on this modified test data.
# In the end, we simply take the median (or mean) value as prediction.
ps <- NULL
dfTest2 <- dfTest
for(s in store_train){
dfTest2$Store[ind_] <- s
p <- predict(gbm_, newdata=dfTest2[ind_,], n.trees=best.iter)
if(!is.null(lambda)){
p <- inverse_transform(p, lambda)
}else{
p <- inverse_transform(p)
}
ps <- rbind(ps, p)
}
p <- apply(ps, 2, median)
pred_test <- c(pred_test, p)
}
}
return(pred_test)
}
#### This function plots the fitted Weekly_Sales for all the combinations
# of Store & specified pred_depts
plotFittedWeekly_Sales <- function(gbm_, GBM_Params, dfTest, dfTrain, pred_depts,
transform_str, inverse_transform, lambda=NULL,
random_seed=2014){
for(dept in pred_depts){
this_dept_store <- sort(unique(dfTest$Store[which(dfTest$Dept==dept)]))
for(store in this_dept_store){
#### Creat the corresponding dir
filePath <- paste('./figures cross dept v1 - bag.fraction',
GBM_Params$bag.fraction,'/',
GBM_Params$distribution,'_',
transform_str,'_',
'weight',holiday_weight,'_',
'RandomSeed', random_seed, sep='')
dir.create(filePath, showWarnings=FALSE, recursive=TRUE)
#### Open png device for plotting
png(paste(filePath, '/GBM_',
'[Ntree',GBM_Params$n.trees,']_',
'[lr', GBM_Params$shrinkage,']_',
'Store', store, '_Dept', dept,'.png', sep=''))
#### Make prediction for testing data of this store and dept combination
dfTest2 <- subset(dfTest, Store==store & Dept==dept)
pred_test <- predTest(gbm_, dfTest2, dfTrain, inverse_transform, lambda)
#### Make prediction for training data of this store and dept combination
dfTrain2 <- subset(dfTrain, Store==store & Dept==dept)
# check if we have Weekly_Slaes in the training data for this
# store and dept combination
if(dim(dfTrain2)[1]>0){
pred_train <- predTest(gbm_, dfTrain2, dfTrain, inverse_transform, lambda)
#### Plot the actual and fitted Weekly_Sales
plot(dfTrain2$Day_Index, dfTrain2$Weekly_Sales,
type='l', col='black', xlim=c(1,180),
main=paste('Store: ', store, ' Dept: ', dept, sep=''),
xlab='Date Index', ylab='Weekly Sales')
points(c(dfTrain2$Day_Index, dfTest2$Day_Index),c(pred_train,pred_test),
type='l', col='red')
}else{
# We don't have, so we just plot the prediction for testing data
#### Plot the fitted Weekly_Sales
plot(dfTest2$Day_Index, pred_test,
type='l', col='red', xlim=c(1,180),
main=paste('Store: ', store, ' Dept: ', dept, sep=''),
xlab='Date Index', ylab='Weekly Sales')
}
dev.off()
gc(reset=T)
}
}
}
#### set the working directory to the path that contains all the data files:
# - ./data/train.csv
# - ./data/test.csv
# - ./data/features.csv
# - ./data/stores.csv
# - ./data/sampleSubmission.csv
#setwd("E:/Walmart")
#setwd("F:/ChenChenglong/R/Walmart")
setwd("F:/陈成龙/R/Walmart/R/git-final")
#setwd("E:/Walmart/R/git-final")
#### put the required packages here
require(gbm)
require(geoR)
require(Hmisc)
#####################
## Preprocess Data ##
#####################
#### Call 'preprocess_data_v1.R' to clean and preprocess the provided data
# source('./preprocess_data_v1.R')
#### Load training and testing data produced by 'preprocess_data_V1.R'
load('./data/training_testing_data_V1.RData')
#####################
## Params Settings ##
#####################
#### number of random seed
# I actually used 10 and averaged those predictions to reduce variance.
# This can give 10~20 improvement.
seed_num <- 1
# random seeds
set.seed(2014) # to ensure reproducable
random_seeds <- sample(10000, seed_num)
#### params for gbm
GBM_Ntrees <- 1000
GBM_Shrinkage <- 0.1
# stochastic GBM to reduce the chance of overfitting
GBM_Bag.fraction <- 0.7
# gaussian seems work better than laplace and quantile
GBM_Distributions <- c('laplace', 'gaussian')[2]
#### setting for holiday weight/response transform
Holiday_Weight <- c(1, 5, 10, 20, 30, 40, 50, 100)[1]
# er... 1 seems work best
Holiday_Weight <- seq(1,5)[1]
#### Settings for response transform
sqr <- function(x){x^2}
## function for Box-Cox transform
BoxCox <- function(x, lambda){
lambda1 <- lambda[1]
lambda2 <- lambda[2]
if(lambda1 == 0){
x1 <- log(x + lambda2)
}else{
x1 <- ((x + lambda2)^lambda1 - 1)/lambda1
}
return(x1)
}
## function for inversed Box-Cox transform
invBoxCox <- function(x1, lambda){
lambda1 <- lambda[1]
lambda2 <- lambda[2]
if(lambda1 == 0){
x <- exp(x1) - lambda2
}else{
x <- (x1*lambda1 + 1)^(1/lambda1) - lambda2
}
return(x)
}
# note the element are FUNCTION
Transform <- c(BoxCox, sqrt, log, identity)[2]
# note the element are STRING
Transform_Str <- c('BoxCox', "sqrt", "log", "identity")[2]
# note the element are FUNCTION
Inverse_Transform <- c(invBoxCox, sqr, exp, identity)[2]
# Note in the above, identity, log, and sqrt are special cases of BoxCox
# with params (lambda1, lambda2), equal to (1,1), (0,0), and (1/2,0), respectively
# Due to time limit, I put BoxCox in high pority. However, sqrt seems work best.
# NOTE:
# When using Box-Cox transform, some of the final prediction maybe NA.
# Therefore, some post-processing might be needed to avoid that being happen.
# One simple approach I took is using the corresponding predictions from sqrt
# transform to replace those NA.
#### debugging?
debug_on <- FALSE
if(debug_on == TRUE){
# plot fitted weekly sales?
plot_fitted_on <- TRUE
# make submission?
save_on <- TRUE
}else{
# plot fitted weekly sales?
plot_fitted_on <- TRUE
# make submission?
save_on <- TRUE
}
##########
## Main ##
##########
dept_type1 = c(1, 18)
dept_type2 = c(2, 4, 8, 60, 79, 80, 81, 87, 90, 91, 92, 93, 94, 97, 98)
dept_type3 = c(3)
dept_type4 = c(5, 6, 7, 14, 17, 21, 22, 23, 25, 26, 27, 29,
32, 46, 48, 55, 59, 72, 82, 85, 96, 99)
dept_type5 = c(9, 10, 19, 30, 34, 35, 37, 52)
dept_type6 = c(24, 31, 33)
dept_type7 = c(11, 36)
dept_type8 = c(12, 16, 56, 95)
dept_type9 = c(13, 20, 42, 49, 50, 83)
dept_type10 = c(28, 40)
dept_type11 = c(41, 44)
dept_type12 = c(67)
dept_type13 = c(71, 74)
depts_list = list(dept_type1, dept_type2, dept_type3, dept_type4, dept_type5,
dept_type6, dept_type7, dept_type8, dept_type9, dept_type10,
dept_type11, dept_type12, dept_type13)
depts_test <- sort(unique(dfTest$Dept))
depts_test <- as.numeric(as.character(depts_test))
dept_alone <- depts_test[!depts_test %in% unlist(depts_list)]
depts_list <- c(depts_list, as.list(dept_alone))
#### Train model
for(count_seed in seq(1, length(random_seeds))){
for(holiday_weight in Holiday_Weight){
for(count_transform in seq(1,length(Transform))){
for(GBM_distribution in GBM_Distributions){
#for(dept in depts_list){
for(dept in depts_list[1]){
#### Set random seed
random_seed <- random_seeds[count_seed]
set.seed(random_seed)
#### Grab params for transform
apply_transform <- Transform[[count_transform]]
transform_str <- Transform_Str[[count_transform]]
inverse_transform <- Inverse_Transform[[count_transform]]
#### Grab params for gbm training
GBM_Params <- list(distribution=GBM_distribution,
n.trees=GBM_Ntrees,
shrinkage=GBM_Shrinkage,
bag.fraction=GBM_Bag.fraction)
#### Verbose
cat('Seed:', count_seed,
'| Holiday Weight:', holiday_weight,
'| Response Transform:', transform_str,
'| GBM Distribution:', GBM_distribution,
'| Dept:', dept,
'\n', sep=' ')
}
}
}
}
}
